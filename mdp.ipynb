{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 88,
=======
   "execution_count": 1,
>>>>>>> Stashed changes
=======
   "execution_count": 39,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
<<<<<<< Updated upstream
    "modules = [\"maxent\", \"optimizer\", \"plot\", \"solver\", \"limiirl\", \"utils\"]\n",
=======
    "from maxent import irl, irl_causal, feature_expectation_from_trajectories\n",
    "import optimizer as O \n",
    "import solver as S                          # MDP solver (value-iteration)\n",
    "import plot as P\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from limiirl import limiirl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [\"maxent\", \"optimizer\", \"plot\", \"solver\", \"limiirl\"]\n",
>>>>>>> Stashed changes
    "def load_modules(modules): \n",
    "    for module in modules:\n",
    "        imported_module = importlib.import_module(module)\n",
    "        importlib.reload(imported_module)\n",
    "\n",
    "\n",
    "load_modules(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from datetime import datetime\n",
    "from maxent import irl, irl_causal, feature_expectation_from_trajectories\n",
    "import optimizer as O \n",
    "import solver as S                          # MDP solver (value-iteration)\n",
    "import plot as P\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from limiirl import limiirl\n",
    "from utils import *\n",
    "import importlib\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load patients, inputevents, and vital signs dataframe from MIMIC-IV \n",
    "\n",
<<<<<<< Updated upstream
=======
    "def fill_NANS(df): \n",
    "\n",
    "    output_df = df.copy() \n",
    "\n",
    "    columns = ['o2sat']\n",
    "\n",
    "    medians = {} \n",
    "\n",
    "    for col in columns: \n",
    "        col_median = df[col].median()\n",
    "        medians[col] = col_median \n",
    "\n",
    "    for index, row in df.iterrows(): \n",
    "        for col in columns: \n",
    "            if math.isnan(row[col]): \n",
    "                df.at[index, col] = medians[col]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> Stashed changes
    "patients_df = read_csv_to_dataframe(\"data/patients.csv\")\n",
    "# prescriptions_df = read_csv_to_dataframe(\"data/prescriptions.csv\")\n",
    "inputevents_df = read_csv_to_dataframe(\"data/inputevents.csv\")\n",
    "# procedureevents_df = read_csv_to_dataframe(\"data/procedureevents.csv\")\n",
    "# d_icd_diagnoses_df = read_csv_to_dataframe(\"data/d_icd_diagnoses.csv\")\n",
    "# triage_df = read_csv_to_dataframe(\"data/triage.csv\")\n",
    "vitalsign_df = read_csv_to_dataframe(\"data/vitalsign.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "# Merge vital signs and patients \n",
    "data_pv = pd.merge(patients_df, vitalsign_df, on='subject_id', how='inner')\n",
    "_ = fill_NANS(data_pv)"
=======
    "data_pv = pd.merge(patients_df, vitalsign_df, on='subject_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>anchor_year_group</th>\n",
       "      <th>dod</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>rhythm</th>\n",
       "      <th>pain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>32952584</td>\n",
       "      <td>2180-07-22 16:36:00</td>\n",
       "      <td>98.4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Sinus Bradycardia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>32952584</td>\n",
       "      <td>2180-07-22 16:43:00</td>\n",
       "      <td>98.4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Sinus Bradycardia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>32952584</td>\n",
       "      <td>2180-07-22 16:45:00</td>\n",
       "      <td>98.4</td>\n",
       "      <td>84.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Sinus Bradycardia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>32952584</td>\n",
       "      <td>2180-07-22 17:56:00</td>\n",
       "      <td>98.4</td>\n",
       "      <td>84.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Sinus Bradycardia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>32952584</td>\n",
       "      <td>2180-07-22 18:37:00</td>\n",
       "      <td>98.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Sinus Bradycardia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564605</th>\n",
       "      <td>19999828</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>2147</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>2164-09-17</td>\n",
       "      <td>32917002</td>\n",
       "      <td>2149-01-08 17:10:00</td>\n",
       "      <td>98.1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Sinus Tachycardia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564606</th>\n",
       "      <td>19999914</td>\n",
       "      <td>F</td>\n",
       "      <td>49</td>\n",
       "      <td>2158</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32002659</td>\n",
       "      <td>2158-12-24 11:43:00</td>\n",
       "      <td>99.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Sinus Tachycardia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564607</th>\n",
       "      <td>19999987</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>2145</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34731548</td>\n",
       "      <td>2145-11-02 19:40:00</td>\n",
       "      <td>99.3</td>\n",
       "      <td>112.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Sinus Tachycardia</td>\n",
       "      <td>unable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564608</th>\n",
       "      <td>19999987</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>2145</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34731548</td>\n",
       "      <td>2145-11-02 20:11:00</td>\n",
       "      <td>99.3</td>\n",
       "      <td>111.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Sinus Tachycardia</td>\n",
       "      <td>unable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564609</th>\n",
       "      <td>19999987</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>2145</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34731548</td>\n",
       "      <td>2145-11-02 21:51:00</td>\n",
       "      <td>99.3</td>\n",
       "      <td>103.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Sinus Tachycardia</td>\n",
       "      <td>unable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1564610 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id gender  anchor_age  anchor_year anchor_year_group  \\\n",
       "0          10000032      F          52         2180       2014 - 2016   \n",
       "1          10000032      F          52         2180       2014 - 2016   \n",
       "2          10000032      F          52         2180       2014 - 2016   \n",
       "3          10000032      F          52         2180       2014 - 2016   \n",
       "4          10000032      F          52         2180       2014 - 2016   \n",
       "...             ...    ...         ...          ...               ...   \n",
       "1564605    19999828      F          46         2147       2017 - 2019   \n",
       "1564606    19999914      F          49         2158       2017 - 2019   \n",
       "1564607    19999987      F          57         2145       2011 - 2013   \n",
       "1564608    19999987      F          57         2145       2011 - 2013   \n",
       "1564609    19999987      F          57         2145       2011 - 2013   \n",
       "\n",
       "                dod   stay_id            charttime  temperature  heartrate  \\\n",
       "0        2180-09-09  32952584  2180-07-22 16:36:00         98.4       83.0   \n",
       "1        2180-09-09  32952584  2180-07-22 16:43:00         98.4       85.0   \n",
       "2        2180-09-09  32952584  2180-07-22 16:45:00         98.4       84.0   \n",
       "3        2180-09-09  32952584  2180-07-22 17:56:00         98.4       84.0   \n",
       "4        2180-09-09  32952584  2180-07-22 18:37:00         98.4       86.0   \n",
       "...             ...       ...                  ...          ...        ...   \n",
       "1564605  2164-09-17  32917002  2149-01-08 17:10:00         98.1      109.0   \n",
       "1564606         NaN  32002659  2158-12-24 11:43:00         99.5       81.0   \n",
       "1564607         NaN  34731548  2145-11-02 19:40:00         99.3      112.0   \n",
       "1564608         NaN  34731548  2145-11-02 20:11:00         99.3      111.0   \n",
       "1564609         NaN  34731548  2145-11-02 21:51:00         99.3      103.0   \n",
       "\n",
       "         resprate  o2sat    sbp   dbp             rhythm    pain  \n",
       "0            24.0   97.0   90.0  51.0  Sinus Bradycardia       0  \n",
       "1            22.0   98.0   76.0  39.0  Sinus Bradycardia       0  \n",
       "2            22.0   97.0   75.0  39.0  Sinus Bradycardia       0  \n",
       "3            20.0   99.0   86.0  51.0  Sinus Bradycardia       0  \n",
       "4            20.0   98.0   65.0  37.0  Sinus Bradycardia       0  \n",
       "...           ...    ...    ...   ...                ...     ...  \n",
       "1564605      15.0   96.0  111.0  78.0  Sinus Tachycardia       0  \n",
       "1564606      10.0  100.0   93.0  55.0  Sinus Tachycardia       0  \n",
       "1564607      18.0   98.0  118.0  83.0  Sinus Tachycardia  unable  \n",
       "1564608      18.0   98.0  123.0  82.0  Sinus Tachycardia  unable  \n",
       "1564609      20.0   98.0  113.0  79.0  Sinus Tachycardia  unable  \n",
       "\n",
       "[1564610 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_NANS(data_pv)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 5,
=======
   "execution_count": 9,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain unique heart rhythms \n",
    "unique_rhythms = data_pv['rhythm'].unique()\n",
    "n_rhythms = len(unique_rhythms)\n",
    "rhythms_mapping = {k:v for k,v in zip(unique_rhythms, range(n_rhythms))}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 6,
=======
   "execution_count": 10,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# features \n",
    "features = [\"gender\", \"anchor_age\", \"temperature\", \"heartrate\", \"resprate\", \"o2sat\", \"sbp\", \"dbp\", \"rhythm\"]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 16,
=======
   "execution_count": 11,
>>>>>>> Stashed changes
=======
   "execution_count": 4,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "M = read_json(\"data/process/M.json\")\n",
    "M = np.array(M)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 9,
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,  52. ,  98.4, ...,  90. ,  51. ,   0. ],\n",
       "       [  1. ,  52. ,  98.4, ...,  76. ,  39. ,   0. ],\n",
       "       [  1. ,  52. ,  98.4, ...,  75. ,  39. ,   0. ],\n",
       "       ...,\n",
       "       [  1. ,  57. ,  99.3, ..., 118. ,  83. ,   4. ],\n",
       "       [  1. ,  57. ,  99.3, ..., 123. ,  82. ,   4. ],\n",
       "       [  1. ,  57. ,  99.3, ..., 113. ,  79. ,   4. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
>>>>>>> Stashed changes
=======
   "execution_count": 5,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_S(M, n_clusters=100, random_state=42): \n",
    "    \"\"\"\n",
    "    M: matrix representation of data \n",
    "\n",
    "    returns a model that takes in a feature set D -> state s from 0 to K - 1\n",
    "    where K is the number of clusters \n",
    "    \"\"\"\n",
    "\n",
    "    # instantiate model and fit data\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state).fit(M)\n",
    "\n",
    "    # return model \n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 10,
=======
   "execution_count": 14,
>>>>>>> Stashed changes
=======
   "execution_count": 6,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "state_model = discretize_S(M)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 11,
=======
   "execution_count": 15,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "inputevents_sample = inputevents_df.sample(n=6000000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 21,
=======
   "execution_count": 16,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = len(inputevents_df['ordercategorydescription'].unique())\n",
    "actions = inputevents_df['ordercategorydescription'].unique() \n",
<<<<<<< Updated upstream
    "action_mapping = {k:v for k, v in zip(actions, range(n_actions))}"
=======
    "\n",
    "action_mapping = {k:v for k, v in zip(actions, range(n_actions))}\n",
    "\n",
    "def action_map(I):\n",
    "    \"\"\"\n",
    "    I: event from inputevent dataframe \n",
    "\n",
    "    returns an action that represents event \n",
    "    \"\"\"\n",
    "\n",
    "    return action_mapping[I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bolus', 'Continuous IV', 'Drug Push', 'Continuous Med',\n",
       "       'Non Iv Meds'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 47,
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_patient_events(events_df): \n",
    "    subject_events = {} \n",
    "    \n",
    "    for _, event in events_df.iterrows(): \n",
    "        subject = event['subject_id']\n",
    "\n",
    "        patient_event = { 'caregiver': event['caregiver_id'], 'starttime': event['starttime'], 'endtime': event['endtime'], 'action': action_map(event['ordercategorydescription']), \"type\": 'action' }\n",
    "\n",
    "        if subject not in subject_events: \n",
    "            value = [patient_event]\n",
    "            subject_events[subject] = value \n",
    "        else: \n",
    "            subject_events[subject].append(patient_event)\n",
    "\n",
    "    # sort these by time\n",
    "    for s in subject_events: \n",
    "        subject_events[s] = sorted(subject_events[s], key=lambda x: x['starttime'])\n",
    "    return subject_events\n",
    "\n",
    "def group_timestamps_by_day(events, key):\n",
    "    timestamp_dict = {}\n",
    "\n",
    "    for event in events:\n",
    "        # Parse the timestamp string into a datetime object\n",
    "        dt = datetime.strptime(event[key], '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Extract the day part (date) from the datetime object\n",
    "        day = dt.date()\n",
    "        \n",
    "        # Convert the date back to a string\n",
    "        day_str = day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Add the timestamp to the corresponding day's list in the dictionary\n",
    "        if day_str not in timestamp_dict:\n",
    "            timestamp_dict[day_str] = [event]\n",
    "        else:\n",
    "            timestamp_dict[day_str].append(event)\n",
    "\n",
    "    return timestamp_dict\n",
    "\n",
    "def find_patient_vitals(data_pv): \n",
    "    subject_vitals = {} \n",
    "    \n",
    "    for _, vitals in data_pv.iterrows(): \n",
    "        subject = vitals['subject_id']\n",
    "\n",
    "        state = state_model.predict(np.array([feature_map(vitals)]))\n",
    "\n",
    "        patient_vital = { 'charttime': vitals['charttime'], 'state': state[0], \"type\": 'state' }\n",
    "        \n",
    "        if subject not in subject_vitals: \n",
    "            value = [patient_vital]\n",
    "            subject_vitals[subject] = value \n",
    "        else: \n",
    "            subject_vitals[subject].append(patient_vital)\n",
    "\n",
    "    # sort these by time\n",
    "    for s in subject_vitals: \n",
    "        subject_vitals[s] = sorted(subject_vitals[s], key=lambda x: x['charttime'])\n",
    "    return subject_vitals\n",
    "\n",
    "\n",
    "def intersect_vitals_events(patient_events, patient_vitals): \n",
    "    new_patient_events = {}\n",
    "    new_patient_vitals = {}\n",
    "\n",
    "    for patient in patient_vitals: \n",
    "        if patient in patient_events: \n",
    "            new_patient_events[patient] = patient_events[patient]\n",
    "            new_patient_vitals[patient] = patient_vitals[patient]\n",
    "\n",
    "    return new_patient_events, new_patient_vitals \n",
    "\n",
    "def trajs_from_patient(event_series, vital_series): \n",
    "    \"\"\"  \n",
    "    event_series: inputevents applied on subject with 'subject_id'\n",
    "    vital_series: vitals recorded for subject with 'subject_id' \n",
    "\n",
    "    iterates through combined event and vitals series S, and in order, for each state s, finds if action \n",
    "    occurs immediately after it?\n",
    "    \"\"\"\n",
    "    # construct trajectory of state action pairs \n",
    "    T = [] \n",
    "\n",
    "    combined_series = sorted(event_series + vital_series, key=lambda x: x['starttime'] if 'starttime' in x else x['charttime'])\n",
    "\n",
    "    n = len(combined_series)\n",
    "\n",
    "    for i in range(n - 1): \n",
    "        event1 = combined_series[i]\n",
    "        event2 = combined_series[i + 1]\n",
    "        if event1['type'] == \"state\" and event2['type'] == 'action': \n",
    "            T.append(event1['state'])\n",
    "            T.append(event2['action'])\n",
    "\n",
    "    # taking the last vital reading that was recorded \n",
    "    # though we should check if this occurs before the last action in T?\n",
    "    # also, issue arises if we have something like [event, vital] which maps to traj [event, vital, event]\n",
    "    # for this we possibly drop trajectories where vital_series has length < 2?\n",
    "    # perhaps, as we loop, we can check the lastest_action to be added \n",
    "    n_vitals = len(vital_series)\n",
    "    T.append(vital_series[n_vitals - 1]['state'])\n",
    "    \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_trajectories(p_events, p_vitals): \n",
    "    \"\"\"\n",
    "    p_events: events for each patient \n",
    "    p_vitals: vital readings for each patient \n",
    "    \"\"\"\n",
    "    trajs = {} \n",
    "    \n",
    "    for patient in p_events: \n",
    "        tau = trajs_from_patient(p_events[patient], p_vitals[patient])\n",
    "        # drop trajectories with length = 0\n",
    "        if (len(tau) > 1):\n",
    "            trajs[int(patient)] = trajs_from_patient(p_events[patient], p_vitals[patient])\n",
    "\n",
    "    return trajs \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 24,
=======
   "execution_count": 20,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_events = find_patient_events(inputevents_sample)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 30,
=======
   "execution_count": 21,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_vitals = find_patient_vitals(data_pv, state_model, features, rhythms_mapping)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 31,
=======
   "execution_count": 22,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce invariant that vital and events data contains entries for both events and vitals   \n",
    "p_events, p_vitals = intersect_vitals_events(patient_events, patient_vitals)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 50,
=======
   "execution_count": 23,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = construct_trajectories(p_events, p_vitals)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(trajectories, \"data/process/trajs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = read_json(\"data/process/trajs.json\")\n",
    "trajectories = { int(k) : v for k, v in zip(trajectories.keys(), trajectories.values()) }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 60,
=======
   "execution_count": 24,
>>>>>>> Stashed changes
=======
   "execution_count": 8,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_traj(trajectories):\n",
    "    lst = []\n",
    "    for patient in trajectories:\n",
    "        traj = trajectories[patient]\n",
    "        row = []\n",
    "        n = len(traj)\n",
    "        for i in range(0, n-2, 2):\n",
    "            row.append((traj[i], traj[i+1], traj[i+2]))\n",
    "        \n",
    "        lst.append(row)\n",
    "    \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 61,
=======
   "execution_count": 25,
>>>>>>> Stashed changes
=======
   "execution_count": 9,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = 0.9\n",
    "num_clusters = 100\n",
    "\n",
    "smoothing_value = 1\n",
    "\n",
    "p_transition = np.zeros((num_clusters, num_clusters, 5)) + smoothing_value"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 62,
=======
   "execution_count": 26,
>>>>>>> Stashed changes
=======
   "execution_count": 11,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "T = convert_traj(trajectories)\n",
    "\n",
    "for traj in T:\n",
    "\n",
    "  for tran in traj:\n",
    "\n",
    "    p_transition[tran[0], tran[2], tran[1]] +=1\n",
    "\n",
    "p_transition = p_transition/ p_transition.sum(axis = 1)[:, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 63,
=======
   "execution_count": 27,
>>>>>>> Stashed changes
=======
   "execution_count": 12,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_states = set()\n",
    "\n",
    "for patient in trajectories:\n",
    "    terminal_states.add(trajectories[patient][-1])\n",
    "\n",
    "terminal_states = list(terminal_states)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 64,
=======
   "execution_count": 28,
>>>>>>> Stashed changes
=======
   "execution_count": 13,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert states and actions to one-hot encoding\n",
    "state_encoder = OneHotEncoder(sparse=False, categories= [np.arange(num_clusters)])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 68,
=======
   "execution_count": 29,
>>>>>>> Stashed changes
=======
   "execution_count": 14,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# set up features: we use one feature vector per state (1 hot encoding for each cluster/state)\n",
    "features = state_encoder.fit_transform(np.arange(num_clusters).reshape(-1, 1))\n",
    "\n",
    "# choose our parameter initialization strategy:\n",
    "#   initialize parameters with constant\n",
    "init = O.Constant(1.0)\n",
    "\n",
    "# choose our optimization strategy:\n",
    "#   we select exponentiated stochastic gradient descent with linear learning-rate decay\n",
    "optim = O.ExpSga(lr=O.linear_decay(lr0=0.2))\n",
    "\n",
    "# actually do some inverse reinforcement learning\n",
    "# reward_maxent = maxent_irl(p_transition, features, terminal_states, trajectories, optim, init, eps= 1e-3)\n",
    "\n",
    "reward_maxent_causal, theta_causal = irl_causal(p_transition, features, terminal_states, T, optim, init, discount,\n",
    "               eps=1e-3, eps_svf=1e-4, eps_lap=1e-4)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 69,
=======
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00418243, 0.99999967, 1.00006515, 0.99999967, 1.00001604,\n",
       "       1.00034348, 0.99999967, 1.00485658, 0.99999967, 1.0003271 ,\n",
       "       1.00037623, 1.00132642, 0.99999967, 1.00171987, 1.00003241,\n",
       "       0.99999967, 1.00093313, 0.99999967, 0.99999967, 0.99999967,\n",
       "       1.00410025, 0.99999967, 0.99999967, 1.00198225, 1.00001604,\n",
       "       1.00026161, 1.00001604, 1.00029435, 1.00042535, 1.00237596,\n",
       "       1.00070378, 0.99999967, 0.99999967, 1.00288473, 1.00027798,\n",
       "       0.99999967, 1.0030489 , 0.99999967, 1.00050723, 1.00145755,\n",
       "       1.00078568, 0.99999967, 1.00011426, 1.0005072 , 1.00027798,\n",
       "       1.00150673, 1.00009789, 1.00072016, 1.00299965, 0.99999967,\n",
       "       1.00132642, 1.00083483, 1.00176906, 1.00016337, 1.00206426,\n",
       "       1.00075292, 1.00339375, 1.0004581 , 1.00462633, 1.0042153 ,\n",
       "       1.00167068, 1.000147  , 1.00034348, 0.99999967, 1.00024523,\n",
       "       1.00242519, 1.00451123, 1.0006055 , 1.0003271 , 1.00227752,\n",
       "       1.00362372, 0.99999967, 1.00144116, 1.00001604, 1.00027798,\n",
       "       1.00163789, 1.00035985, 1.00011426, 1.00194945, 1.00013063,\n",
       "       1.00459344, 1.00090036, 1.00112976, 1.00144116, 0.99999967,\n",
       "       1.00216268, 1.00691472, 1.00006515, 1.00035985, 1.00314742,\n",
       "       1.00231033, 1.00147395, 1.00093313, 1.00749172, 1.00716198,\n",
       "       1.00003241, 1.00299965, 0.99999967, 1.00031073, 1.00047448])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_maxent_causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
>>>>>>> Stashed changes
=======
   "execution_count": 15,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_policy(p_transition, reward, discount=0.9):\n",
    "    \"\"\" \n",
    "    p_transition: transition probabilities\n",
    "    reward: reward function \n",
    "    discount: discount factor \n",
    "\n",
    "    calculates V and Q function using value iteration \n",
    "    \n",
    "    returns softmax policy and policy \n",
    "    \"\"\" \n",
    "    V, Q = S.value_iteration(p_transition, reward, discount)\n",
    "    Q = Q.reshape((5, num_clusters))\n",
    "\n",
    "    # get softmax policy \n",
    "    soft_pi = (np.exp(Q)/ np.sum(np.exp(Q), axis = 0)).T\n",
    "    policy = np.argmax(Q, axis = 0).reshape(-1, )\n",
    "\n",
    "    return policy, soft_pi "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 70,
=======
   "execution_count": 32,
>>>>>>> Stashed changes
=======
   "execution_count": 16,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "V, Q = S.value_iteration(p_transition, reward_maxent_causal, discount)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 71,
=======
   "execution_count": 33,
>>>>>>> Stashed changes
=======
   "execution_count": 17,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Q.reshape((5, num_clusters))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 72,
=======
   "execution_count": 34,
>>>>>>> Stashed changes
=======
   "execution_count": 18,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_pi_mce = (np.exp(Q)/ np.sum(np.exp(Q), axis = 0)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soft_pi_mce"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 73,
=======
   "execution_count": 35,
>>>>>>> Stashed changes
=======
   "execution_count": 19,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_mce = np.argmax(Q, axis = 0).reshape(-1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "policy_mce"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 93,
=======
   "execution_count": 36,
>>>>>>> Stashed changes
=======
   "execution_count": 20,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "n_patients = 100 \n",
    "K = 5\n",
    "gamma = 0.9\n",
    "\n",
    "\n",
    "random_patients = random.sample(list(trajectories.keys()), n_patients)\n",
    "\n",
    "trajectories_s = { patient: trajectories[patient] for patient in random_patients }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 75,
=======
   "execution_count": 37,
>>>>>>> Stashed changes
=======
   "execution_count": 21,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(tau, f, gamma): \n",
    "    \"\"\"\n",
    "    phi is a feature-based function that maps a trajectory `tau` -> R \n",
    "    \n",
    "    tau: trajectory of the form (s_1, a_1, s_2, a_2, ..., s_{|tau|})\n",
    "    f: feature function: S -> R\n",
    "    gamma: discount factor \n",
    "\n",
    "    phi(tau) = \\sum_{t = 1}^{|tau|}} gamma^{t - 1}phi(s_t) \n",
    "\n",
    "    define |tau| as number of (s_t, a_t, s_{t + 1}) tuples \n",
    "    \"\"\"\n",
    "\n",
    "    n = len(tau)\n",
    "    return np.sum([(gamma ** (i // 2)) * f[tau[i]]  for i in range(0, n, 2)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 76,
=======
   "execution_count": 38,
>>>>>>> Stashed changes
=======
   "execution_count": 22,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "f = feature_expectation_from_trajectories(features, T)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 77,
=======
   "execution_count": 39,
>>>>>>> Stashed changes
=======
   "execution_count": 23,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_trajectories(taus, gamma=0.9): \n",
    "    \"\"\" \n",
    "    taus: dictionary of the form { patient: tau } where tau is the patient's trajectory \n",
    "    during stay in ICU (from MIMIC dataset)\n",
    "\n",
    "    gamma: discount factor \n",
    "\n",
    "    returns X of shape N x d, where N is the number of trajectories and d represents number of features \n",
    "    \"\"\"\n",
    "    X = [] \n",
    "\n",
    "    for patient in taus: \n",
    "        traj = taus[patient] \n",
    "        phi_t = phi(traj, f, gamma)\n",
    "        X.append([phi_t])\n",
    "\n",
    "    return np.array(X)    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 78,
=======
   "execution_count": 40,
>>>>>>> Stashed changes
=======
   "execution_count": 24,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_trajectories(trajectories_s)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 79,
=======
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 75\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
>>>>>>> Stashed changes
=======
   "execution_count": 25,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_trajectories(X, n_experts=100): \n",
    "    \"\"\"\n",
    "    X: feature representation of trajectories\n",
    "    n_experts: assume trajectories come from `n_experts` experts \n",
    "\n",
    "    performs kmeans clustering on X and returns model \n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_experts, random_state=42).fit(X)\n",
    "\n",
    "    return kmeans "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 80,
=======
   "execution_count": 43,
>>>>>>> Stashed changes
=======
   "execution_count": 26,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cluster_model = cluster_trajectories(X, n_experts=K)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 55,
=======
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "n = len(X) \n",
    "u = np.zeros((n, K))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(K):\n",
    "        c = cluster_model.predict([X[i]])\n",
    "        u[i][j] = 1 if c == j else 0\n",
    "    print(i)      \n",
    "rho = np.zeros(K)\n",
    "for k in range(K): \n",
    "    print(k)      \n",
    "    rho[k] = np.sum([u[i][k] for i in range(n)], axis=0) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {} # key: cluster, value: 2d list with the trajectories in that cluster \n",
    "\n",
    "for patient in trajectories: \n",
    "    traj = trajectories[patient]\n",
    "    phi_t = phi(traj, f, gamma)\n",
    "    cluster = cluster_model.predict([[phi_t]])[0]\n",
    "    if not cluster in data: \n",
    "        data[cluster] = [traj]\n",
    "    else: \n",
    "        data[cluster].append(traj)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 81,
=======
   "execution_count": 46,
>>>>>>> Stashed changes
=======
   "execution_count": 27,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_traj(trajectories):\n",
    "    lst = []\n",
    "    for traj in trajectories:\n",
    "        row = []\n",
    "        n = len(traj)\n",
    "        for i in range(0, n-2, 2):\n",
    "            row.append((traj[i], traj[i+1], traj[i+2]))\n",
    "        \n",
    "        lst.append(row)\n",
    "    \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 83,
=======
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limiirl_start(): \n",
    "    init_reward_policies = {}  # key: each cluster denoted as element in [K], value: { reward, policy, theta }\n",
    "    theta_mle = np.zeros((K, 100))\n",
    "\n",
    "    i = 0 \n",
    "    for cluster in data: \n",
    "        num_clusters = 100\n",
    "\n",
    "        smoothing_value = 1\n",
    "\n",
    "        p_transition = np.zeros((num_clusters, num_clusters, 5)) + smoothing_value\n",
    "\n",
    "        T = format_traj(data[cluster])\n",
    "\n",
    "        for traj in T:\n",
    "\n",
    "            for tran in traj:\n",
    "\n",
    "                p_transition[tran[0], tran[2], tran[1]] +=1\n",
    "\n",
    "        p_transition = p_transition/ p_transition.sum(axis = 1)[:, np.newaxis, :]\n",
    "\n",
    "\n",
    "        terminal_states = set()\n",
    "\n",
    "        for traj in data[cluster]:\n",
    "            terminal_states.add(traj[-1])\n",
    "\n",
    "        terminal_states = list(terminal_states)\n",
    "\n",
    "        init = O.Constant(1.0)\n",
    "\n",
    "        # choose our optimization strategy:\n",
    "        #   we select exponentiated stochastic gradient descent with linear learning-rate decay\n",
    "        optim = O.ExpSga(lr=O.linear_decay(lr0=0.2))\n",
    "\n",
    "        # actually do some inverse reinforcement learning\n",
    "        # reward_maxent = maxent_irl(p_transition, features, terminal_states, trajectories, optim, init, eps= 1e-3)\n",
    "\n",
    "        reward, theta = irl_causal(p_transition, features, terminal_states, T, optim, init, gamma,\n",
    "                    eps=1e-3, eps_svf=1e-4, eps_lap=1e-4)\n",
    "        \n",
    "        V, Q = S.value_iteration(p_transition, reward, gamma)\n",
    "\n",
    "        pi = np.argmax(Q, axis = 0).reshape(-1, )  \n",
    "\n",
    "        init_reward_policies[cluster] = { \"reward\": reward, \"policy\": pi, \"theta\": theta }\n",
    "\n",
    "        theta_mle[cluster] = theta \n",
    "\n",
    "        i += 1 \n",
    "        print(i)\n",
    "  \n",
    "    return init_reward_policies, theta_mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 81 is out of bounds for axis 0 with size 75",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m traj_models, theta_mle \u001b[38;5;241m=\u001b[39m \u001b[43mlimiirl_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 49\u001b[0m, in \u001b[0;36mlimiirl_start\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m pi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(Q, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, )  \n\u001b[1;32m     47\u001b[0m init_reward_policies[cluster] \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m: reward, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m: pi, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m\"\u001b[39m: theta }\n\u001b[0;32m---> 49\u001b[0m \u001b[43mtheta_mle\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m theta \n\u001b[1;32m     51\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 81 is out of bounds for axis 0 with size 75"
     ]
    }
   ],
   "source": [
    "traj_models, theta_mle = limiirl_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": 28,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(traj, theta, gamma=0.9): \n",
    "    # calculate reward \n",
    "    reward = features.dot(theta)\n",
    "\n",
    "    V, Q = S.value_iteration(p_transition, reward, gamma)\n",
    "    # calculate policy using softmax selection model \n",
    "\n",
    "    Q = Q.reshape((5, num_clusters))\n",
    "    soft_pi = (np.exp(Q)/ np.sum(np.exp(Q), axis = 0)).T\n",
    "     \n",
    "    prod = 1 \n",
    "    n = len(traj)\n",
    "    for i in range(0, n - 1, 2): \n",
    "        state = traj[i]\n",
    "        action = traj[i + 1]\n",
    "        prod *= soft_pi[state][action]\n",
    "\n",
    "    return prod "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
<<<<<<< Updated upstream
=======
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soft_pi_mce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jaydenpersonnat/MI-IRL/mdp.ipynb Cell 52\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jaydenpersonnat/MI-IRL/mdp.ipynb#Y104sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m soft_pi_mce\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soft_pi_mce' is not defined"
     ]
    }
   ],
   "source": [
    "soft_pi_mce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# N = 20 \n",
    "\n",
    "# x = np.arange(100)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# # Plotting each dataset on the same axes with a label for the legend\n",
    "# ax.plot(x, reward_maxent_causal, label='Single Intention')\n",
    "\n",
    "# for i in range(N): \n",
    "#     ax.plot(x, traj_models[i]['reward'], label=f'MI: Expert_{i}')\n",
    "   \n",
    "\n",
    "# # Adding the legend, which uses the labels specified in the plot commands\n",
    "# ax.legend()\n",
    "\n",
    "# # Setting the x-axis and y-axis labels\n",
    "# ax.set_xlabel('state')\n",
    "# ax.set_ylabel('reward')\n",
    "\n",
    "# # Setting the x-axis range from 0 to 99\n",
    "# ax.set_xlim([0, 99])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 90,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": 29,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 10\n",
    "taus = list(trajectories_s.values())\n",
    "epsilon = 0.005"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< Updated upstream
   "execution_count": 94,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": 41,
>>>>>>> 1995886 (push init version of limiirl)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiMIIRL: cluster 0\n",
      "LiMIIRL: cluster 1\n",
      "LiMIIRL: cluster 2\n",
      "LiMIIRL: cluster 3\n",
      "LiMIIRL: cluster 4\n",
      "---Finished Light-weight start\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "rho, theta, u = limiirl(X, taus, features, cluster_model, num_clusters, max_iter=4, K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_policy(pi, state, N=1000): \n",
    "    dist = pi[state]\n",
    "\n",
    "    actions = np.arange(len(dist))\n",
    "    sampled_actions = np.random.choice(actions, size=N, p=dist)\n",
    "\n",
    "    return sampled_actions  \n",
    "\n",
    "def policy_dist(pi_one, pi_two):\n",
    "    # soft policies - distribution of actions for each state \n",
    "\n",
    "    dist_vect = [] \n",
    "    for s in range(num_clusters): \n",
    "        sample_one = sample_policy(pi_one, s)\n",
    "        sample_two = sample_policy(pi_two, s)\n",
    "        dist_vect.append(wasserstein_distance(sample_one, sample_two)) \n",
    "\n",
    "    \n",
    "    return np.mean(dist_vect)\n",
    "\n",
    "def cmp_single(expert_policies, single_policy): \n",
    "    \"\"\"\n",
    "    expert_policies: arr of policies of shape K x |S| x |A|  \n",
    "    single_policy: policy of shape |S| x |A| \n",
    "    returns a vector of distances comparing kth expert with single intention model\n",
    "    \"\"\"\n",
    "\n",
    "    dist_vect = [] \n",
    "    for expert_pi in expert_policies: \n",
    "        dist = policy_dist(expert_pi, single_policy)\n",
    "        dist_vect.append(dist)\n",
    "\n",
    "    return np.array(dist_vect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
