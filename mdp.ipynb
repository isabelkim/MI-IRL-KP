{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "modules = [\"maxent\", \"optimizer\", \"plot\", \"solver\", \"limiirl\", \"utils\"]\n",
    "def load_modules(modules): \n",
    "    for module in modules:\n",
    "        imported_module = importlib.import_module(module)\n",
    "        importlib.reload(imported_module)\n",
    "\n",
    "\n",
    "load_modules(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from maxent import irl, irl_causal, feature_expectation_from_trajectories\n",
    "import optimizer as O \n",
    "import solver as S                          # MDP solver (value-iteration)\n",
    "import plot as P\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from limiirl import limiirl, phi, find_policy\n",
    "from utils import *\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = read_json(\"data/process/M.json\")\n",
    "M = np.array(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = read_json(\"data/process/trajs.json\")\n",
    "trajectories = { int(k) : v for k, v in zip(trajectories.keys(), trajectories.values()) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_traj(trajectories):\n",
    "    lst = []\n",
    "    for patient in trajectories:\n",
    "        traj = trajectories[patient]\n",
    "        row = []\n",
    "        n = len(traj)\n",
    "        for i in range(0, n-2, 2):\n",
    "            row.append((traj[i], traj[i+1], traj[i+2]))\n",
    "        \n",
    "        lst.append(row)\n",
    "    \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = 100 \n",
    "actions = 5 \n",
    "discount = 0.9 \n",
    "T = convert_traj(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tran_model(taus, states=100, smoothing_value=1): \n",
    "    p_transition = np.zeros((states, states, actions)) + smoothing_value\n",
    "\n",
    "    for traj in taus:\n",
    "        for tran in traj:\n",
    "\n",
    "            p_transition[tran[0], tran[2], tran[1]] +=1\n",
    "\n",
    "        p_transition = p_transition/ p_transition.sum(axis = 1)[:, np.newaxis, :]\n",
    "\n",
    "    return p_transition\n",
    "\n",
    "def calc_terminal_states(taus): \n",
    "    terminal_states = set() \n",
    "\n",
    "    for patient in taus: \n",
    "        terminal_states.add(taus[patient][-1])\n",
    "    \n",
    "    return list(terminal_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert states and actions to one-hot encoding\n",
    "state_encoder = OneHotEncoder(sparse=False, categories= [np.arange(states)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate starting state probabilities \n",
    "def calc_start_dist(taus, S): \n",
    "    X = np.zeros(S)\n",
    "    n = len(taus)\n",
    "\n",
    "    for tau in taus: \n",
    "        X[tau[0]] += 1 \n",
    "\n",
    "    return X / n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaydenpersonnat/MI-IRL/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "p_0 = calc_start_dist(list(trajectories.values()), states)\n",
    "terminal_states = calc_terminal_states(trajectories)\n",
    "p_transition = calc_tran_model(T, states=states)\n",
    "features = state_encoder.fit_transform(np.arange(states).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_intent(): \n",
    "    # set up features: we use one feature vector per state (1 hot encoding for each cluster/state)\n",
    "    # choose our parameter initialization strategy:\n",
    "    #   initialize parameters with constant\n",
    "    init = O.Constant(1.0)\n",
    "\n",
    "    # choose our optimization strategy:\n",
    "    #   we select exponentiated stochastic gradient descent with linear learning-rate decay\n",
    "    optim = O.ExpSga(lr=O.linear_decay(lr0=0.2))\n",
    "\n",
    "    # actually do some inverse reinforcement learning\n",
    "    # reward_maxent = maxent_irl(p_transition, features, terminal_states, trajectories, optim, init, eps= 1e-3)\n",
    "\n",
    "    reward_maxent_causal, theta_causal = irl_causal(p_transition, features, terminal_states, T, optim, init, discount,\n",
    "                eps=1e-3, eps_svf=1e-4, eps_lap=1e-4)\n",
    "    \n",
    "    return reward_maxent_causal, theta_causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_single, theta_single = train_single_intent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, soft_pi = find_policy(p_transition, reward_single, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "n_patients = 500 \n",
    "K = 25\n",
    "gamma = 0.9\n",
    "\n",
    "\n",
    "random_patients = random.sample(list(trajectories.keys()), n_patients)\n",
    "\n",
    "trajectories_s = { patient: trajectories[patient] for patient in random_patients }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = feature_expectation_from_trajectories(features, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_trajectories(taus, gamma=0.9): \n",
    "    \"\"\" \n",
    "    taus: dictionary of the form { patient: tau } where tau is the patient's trajectory \n",
    "    during stay in ICU (from MIMIC dataset)\n",
    "\n",
    "    gamma: discount factor \n",
    "\n",
    "    returns X of shape N x d, where N is the number of trajectories and d represents number of features \n",
    "    \"\"\"\n",
    "    X = [] \n",
    "\n",
    "    for patient in taus: \n",
    "        traj = taus[patient] \n",
    "        phi_t = phi(traj, f, gamma)\n",
    "        X.append([phi_t])\n",
    "\n",
    "    return np.array(X)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_trajectories(trajectories_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_trajectories(X, n_experts=100): \n",
    "    \"\"\"\n",
    "    X: feature representation of trajectories\n",
    "    n_experts: assume trajectories come from `n_experts` experts \n",
    "\n",
    "    performs kmeans clustering on X and returns model \n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_experts, random_state=42).fit(X)\n",
    "\n",
    "    return kmeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaydenpersonnat/MI-IRL/.venv/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "cluster_model = cluster_trajectories(X, n_experts=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 10\n",
    "taus = list(trajectories_s.values())\n",
    "epsilon = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, theta, u = limiirl(X, taus, features, cluster_model, states, f=f, p_transition=p_transition, p_0=p_0,  transition=p_transition, max_iter=30, K=K, descent_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('data/experiments/trial_1700973935.523698.json.npz') as data:\n",
    "    rho = data['rho']\n",
    "    u = data['u']\n",
    "    theta = data['theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_experts = [find_policy(p_transition, features.dot(th), states)[1] for th in theta]\n",
    "_, soft_single = find_policy(p_transition, features.dot(theta_single), states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_policy(pi, state, N=1000): \n",
    "    dist = pi[state]\n",
    "\n",
    "    actions = np.arange(len(dist))\n",
    "    sampled_actions = np.random.choice(actions, size=N, p=dist)\n",
    "\n",
    "    return sampled_actions  \n",
    "\n",
    "def policy_dist(pi_one, pi_two):\n",
    "    # soft policies - distribution of actions for each state \n",
    "\n",
    "    dist_vect = [] \n",
    "    for s in range(states): \n",
    "        sample_one = sample_policy(pi_one, s)\n",
    "        sample_two = sample_policy(pi_two, s)\n",
    "        dist_vect.append(wasserstein_distance(sample_one, sample_two)) \n",
    "\n",
    "    \n",
    "    return np.mean(dist_vect)\n",
    "\n",
    "def cmp_single(expert_policies, single_policy): \n",
    "    \"\"\"\n",
    "    expert_policies: arr of policies of shape K x |S| x |A|  \n",
    "    single_policy: policy of shape |S| x |A| \n",
    "    returns a vector of distances comparing kth expert with single intention model\n",
    "    \"\"\"\n",
    "\n",
    "    dist_vect = [] \n",
    "    for expert_pi in expert_policies: \n",
    "        dist = policy_dist(expert_pi, single_policy)\n",
    "        dist_vect.append(dist)\n",
    "\n",
    "    return np.array(dist_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_from_single = cmp_single(soft_experts, soft_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07357, 0.06769, 0.06751, 0.06475, 0.10159, 0.06796, 0.06757,\n",
       "       0.08334, 0.08896, 0.66428])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
